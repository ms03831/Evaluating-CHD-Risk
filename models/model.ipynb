{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[621, 101],\n",
       "       [ 14,  14]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest:  0.8466666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[634, 111],\n",
       "       [  1,   4]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier:  0.8506666666666667\n",
      "Linear SVM:  0.848\n",
      "Guassian NaiveBayes:  0.8346666666666667\n",
      "MLP Classifier:  0.8506666666666667\n",
      "Logistic Regression:  0.8506666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from helperFunctions import *\n",
    "\n",
    "import numpy as np \n",
    "from sklearn.metrics import accuracy_score\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.target = None\n",
    "        self.features = None\n",
    "        self.data = None\n",
    "        self.testX = None\n",
    "        self.testY = None\n",
    "        self.trainX = None\n",
    "        self.trainY = None\n",
    "        \n",
    "    def _readDataset(self, filename):\n",
    "        self.data = pd.read_csv(filename)\n",
    "\n",
    "    def _dropNulls(self):\n",
    "        self.data.drop([\"education\"], axis = 1, inplace = True) #dropping this improved accuracy\n",
    "        self.data.dropna(inplace = True)\n",
    "    \n",
    "    def _saveProcessedData(self):\n",
    "        self.data.to_csv(\"../data/processedData.csv\")\n",
    "        self.data = self.data.apply(lambda x: normalize(x))\n",
    "        self.features = self.data.drop(\"TenYearCHD\", axis = 1)\n",
    "        self.target = self.data.TenYearCHD\n",
    "        \n",
    "    def _trainTestSplit(self):\n",
    "        self.trainX, self.testX, self.trainY, self.testY = train_test_split(self.features, self.target, test_size=0.2)\n",
    "    \n",
    "    def preProcessing(self, filename):\n",
    "        self._readDataset(filename)\n",
    "        self._dropNulls()\n",
    "        self.data.reset_index(drop = True)\n",
    "        self._saveProcessedData()\n",
    "        self._trainTestSplit()\n",
    "        #display(self.data.corr())\n",
    "    \n",
    "    def fit_model(self):\n",
    "        rf = RandomForestClassifier()\n",
    "        gnb = GaussianNB()\n",
    "        svm = LinearSVC()\n",
    "        mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(10),max_iter=10)\n",
    "        lm = LogisticRegression(solver = 'lbfgs', max_iter = 1000)\n",
    "        \n",
    "        lm.fit(np.array(self.trainX), np.array(self.trainY))\n",
    "        gnb.fit(np.array(self.trainX), np.array(self.trainY))\n",
    "        rf.fit(np.array(self.trainX), np.array(self.trainY))\n",
    "        svm.fit(np.array(self.trainX), np.array(self.trainY))\n",
    "        mlp.fit(np.array(self.trainX), np.array(self.trainY))\n",
    "    \n",
    "        predictions = rf.predict(self.testX)\n",
    "        display(confusion_matrix(predictions, self.testY))\n",
    "        print(\"RandomForest: \" , accuracy_score(predictions, self.testY), end = '\\n')\n",
    "        predictions = mlp.predict(self.testX)\n",
    "        display(confusion_matrix(mlp.predict(self.testX), self.testY))\n",
    "        print(\"MLP Classifier: \" , accuracy_score(predictions, self.testY), end = '\\n')\n",
    "        predictions = svm.predict(self.testX)\n",
    "        print(\"Linear SVM: \" , accuracy_score(predictions, self.testY), end = '\\n')\n",
    "        predictions = gnb.predict(self.testX)\n",
    "        print(\"Guassian NaiveBayes: \" , accuracy_score(predictions, self.testY), end = '\\n')\n",
    "        predictions = mlp.predict(self.testX)\n",
    "        print(\"MLP Classifier: \" , accuracy_score(predictions, self.testY), end = '\\n')\n",
    "        predictions = lm.predict(self.testX)\n",
    "        print(\"Logistic Regression: \" , accuracy_score(predictions, self.testY), end = '\\n')\n",
    "        \n",
    "\n",
    "model = Model()\n",
    "model.preProcessing(\"../data/framingham.csv\")\n",
    "model.fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['male', 'age', 'currentSmoker', 'cigsPerDay', 'BPMeds',\n",
       "       'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n",
       "       'diaBP', 'BMI', 'heartRate', 'glucose'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.testX.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
